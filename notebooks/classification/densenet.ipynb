{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a62a7996",
   "metadata": {},
   "source": [
    "# DenseNet\n",
    "\n",
    "---\n",
    "\n",
    "### 背景和尝试解决的问题\n",
    "\n",
    "- **ResNet后的新挑战**：  \n",
    "  ResNet通过残差连接缓解了梯度消失问题，但每层仅与相邻层相加，特征复用效率有限。深层网络中，特征的逐层传递可能导致信息逐渐稀释。\n",
    "- **参数冗余问题**：  \n",
    "  传统CNN（如VGG、ResNet）通过堆叠层数提升性能，但参数利用率低，大量重复的特征提取导致计算成本高昂。\n",
    "- **梯度消失残留风险**：  \n",
    "  尽管ResNet改善了梯度传播，但在极深层网络中（如1000层以上），梯度衰减问题仍未完全消除。\n",
    "\n",
    "**DenseNet目标**：  \n",
    "通过密集跨层连接最大化特征复用，减少参数冗余，同时进一步优化梯度流动（由Gao Huang等人在2017年提出）。\n",
    "\n",
    "---\n",
    "\n",
    "![alt text](resources/densenet_arch.png \"Title\")\n",
    "\n",
    "## 创新点\n",
    "\n",
    "### 密集连接（Dense Connectivity）\n",
    "- **密集块（Dense Block）设计**：  \n",
    "  每一层的输入来自前面所有层的输出（例如第$L$层的输入为$[x_0, x_1, ..., x_{L-1}]$，其中$x_i$为第$i$层的特征图），通过**通道维度拼接**（Concatenation）而非ResNet的加法。\n",
    "- **特征复用与多样性**：  \n",
    "  每一层均可访问所有前置层的特征，避免重复提取，鼓励网络学习新特征（即“集体知识”）。\n",
    "\n",
    "### 关键组件设计\n",
    "- **增长率（Growth Rate $k$）**：  \n",
    "  控制每层输出特征图的通道数（例如$k=32$），密集块内每层的输出通道固定为$k$，但拼接后的输入通道数线性增长。\n",
    "- **过渡层（Transition Layer）**：  \n",
    "  位于密集块之间，包含：\n",
    "  - 1×1卷积（压缩通道数）\n",
    "  - 2×2平均池化（降采样）\n",
    "- **瓶颈层（Bottleneck Layer）**：  \n",
    "  在密集块内，每层先通过1×1卷积降维（减少计算量），再进行3×3卷积。\n",
    "\n",
    "### 优势\n",
    "- **参数高效**：  \n",
    "  DenseNet-201（20M参数）在ImageNet上性能优于ResNet-152（60M参数）。\n",
    "- **梯度流动增强**：  \n",
    "  反向传播时梯度可直达所有前置层，彻底消除梯度消失问题。\n",
    "- **隐式深度监督**：  \n",
    "  浅层特征直接参与深层计算，相当于自动引入中间监督信号。\n",
    "\n",
    "![alt text](resources/densenet_loss_surface.png \"Title\")\n",
    "\n",
    "[Visualizing the Loss Landscape of Neural Nets](https://arxiv.org/pdf/1712.09913)也指出,DenseNet的损失函数更加平滑,更容易收敛。\n",
    "\n",
    "![alt text](resources/densenet_detail.png \"Title\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63089980",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae655c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device:  cuda\n"
     ]
    }
   ],
   "source": [
    "# 自动重新加载外部module，使得修改代码之后无需重新import\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from hdd.device.utils import get_device\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 设置训练数据的路径\n",
    "DATA_ROOT = \"~/workspace/hands-dirty-on-dl/dataset\"\n",
    "# 设置TensorBoard的路径\n",
    "TENSORBOARD_ROOT = \"~/workspace/hands-dirty-on-dl/dataset\"\n",
    "# 设置预训练模型参数路径\n",
    "TORCH_HUB_PATH = \"~/workspace/hands-dirty-on-dl/pretrained_models\"\n",
    "torch.hub.set_dir(TORCH_HUB_PATH)\n",
    "# 挑选最合适的训练设备\n",
    "DEVICE = get_device([\"cuda\", \"cpu\"])\n",
    "print(\"Use device: \", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e02b05f",
   "metadata": {},
   "source": [
    "## Experiment on cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f55268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Basic Info of train dataset: \n",
      " Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: /home/tf/workspace/hands-dirty-on-dl/dataset\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Pad(padding=4, fill=0, padding_mode=constant)\n",
      "               RandomRotation(degrees=[-3.0, 3.0], interpolation=nearest, expand=False, fill=0)\n",
      "               RandomCrop(size=(32, 32), padding=None)\n",
      "               RandomHorizontalFlip(p=0.5)\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.50707516, 0.48654887, 0.44091784], std=[0.26733429, 0.25643846, 0.27615047])\n",
      "           )\n",
      "Basic Info of test dataset: \n",
      " Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: /home/tf/workspace/hands-dirty-on-dl/dataset\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=[0.50707516, 0.48654887, 0.44091784], std=[0.26733429, 0.25643846, 0.27615047])\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# 我们提前计算好了训练数据集上的均值和方差\n",
    "TRAIN_MEAN = [0.50707516, 0.48654887, 0.44091784]\n",
    "TRAIN_STD = [0.26733429, 0.25643846, 0.27615047]\n",
    "\n",
    "train_dataset_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Pad(4),\n",
    "        transforms.RandomRotation(3),\n",
    "        transforms.RandomCrop(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=TRAIN_MEAN, std=TRAIN_STD),\n",
    "    ]\n",
    ")\n",
    "# 加载数据集\n",
    "train_dataset = datasets.CIFAR10(\n",
    "    root=DATA_ROOT,\n",
    "    train=True,\n",
    "    transform=train_dataset_transforms,\n",
    "    download=True,\n",
    ")\n",
    "val_dataset = datasets.CIFAR10(\n",
    "    root=DATA_ROOT,\n",
    "    train=False,\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize(TRAIN_MEAN, TRAIN_STD)]\n",
    "    ),\n",
    "    download=True,\n",
    ")\n",
    "print(\"Basic Info of train dataset: \\n\", train_dataset)\n",
    "print(\"Basic Info of test dataset: \\n\", val_dataset)\n",
    "BATCH_SIZE = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6c774c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/130 Train Loss: 1.6259 Accuracy: 0.4048 Time: 17.50240  | Val Loss: 2.0252 Accuracy: 0.3826\n",
      "Epoch: 2/130 Train Loss: 1.1345 Accuracy: 0.5932 Time: 17.42568  | Val Loss: 1.0998 Accuracy: 0.6200\n",
      "Epoch: 3/130 Train Loss: 0.9300 Accuracy: 0.6678 Time: 18.33759  | Val Loss: 1.2027 Accuracy: 0.6291\n",
      "Epoch: 4/130 Train Loss: 0.7972 Accuracy: 0.7187 Time: 18.79990  | Val Loss: 0.7491 Accuracy: 0.7463\n",
      "Epoch: 5/130 Train Loss: 0.7043 Accuracy: 0.7551 Time: 17.04572  | Val Loss: 0.8644 Accuracy: 0.7237\n",
      "Epoch: 6/130 Train Loss: 0.6399 Accuracy: 0.7790 Time: 19.28985  | Val Loss: 0.5805 Accuracy: 0.8041\n",
      "Epoch: 7/130 Train Loss: 0.5905 Accuracy: 0.7961 Time: 17.71463  | Val Loss: 0.7037 Accuracy: 0.7720\n",
      "Epoch: 8/130 Train Loss: 0.5575 Accuracy: 0.8059 Time: 18.67479  | Val Loss: 0.5547 Accuracy: 0.8204\n",
      "Epoch: 9/130 Train Loss: 0.5324 Accuracy: 0.8165 Time: 17.52033  | Val Loss: 0.5621 Accuracy: 0.8162\n",
      "Epoch: 10/130 Train Loss: 0.5121 Accuracy: 0.8241 Time: 19.09249  | Val Loss: 0.6853 Accuracy: 0.7776\n",
      "Epoch: 11/130 Train Loss: 0.4852 Accuracy: 0.8332 Time: 18.84441  | Val Loss: 0.6144 Accuracy: 0.8043\n",
      "Epoch: 12/130 Train Loss: 0.4607 Accuracy: 0.8400 Time: 17.53686  | Val Loss: 0.6846 Accuracy: 0.7801\n",
      "Epoch: 13/130 Train Loss: 0.4532 Accuracy: 0.8439 Time: 17.19757  | Val Loss: 0.5392 Accuracy: 0.8242\n",
      "Epoch: 14/130 Train Loss: 0.4387 Accuracy: 0.8496 Time: 16.93452  | Val Loss: 0.4810 Accuracy: 0.8363\n",
      "Epoch: 15/130 Train Loss: 0.4296 Accuracy: 0.8519 Time: 17.78425  | Val Loss: 0.4772 Accuracy: 0.8374\n",
      "Epoch: 16/130 Train Loss: 0.4165 Accuracy: 0.8564 Time: 17.55876  | Val Loss: 0.4985 Accuracy: 0.8438\n",
      "Epoch: 17/130 Train Loss: 0.4084 Accuracy: 0.8593 Time: 17.69393  | Val Loss: 0.4348 Accuracy: 0.8532\n",
      "Epoch: 18/130 Train Loss: 0.4006 Accuracy: 0.8609 Time: 18.27415  | Val Loss: 0.5365 Accuracy: 0.8226\n",
      "Epoch: 19/130 Train Loss: 0.3967 Accuracy: 0.8624 Time: 16.80787  | Val Loss: 0.4810 Accuracy: 0.8381\n",
      "Epoch: 20/130 Train Loss: 0.3879 Accuracy: 0.8677 Time: 18.39507  | Val Loss: 0.4559 Accuracy: 0.8521\n",
      "Epoch: 21/130 Train Loss: 0.3826 Accuracy: 0.8665 Time: 18.55082  | Val Loss: 0.6705 Accuracy: 0.7908\n",
      "Epoch: 22/130 Train Loss: 0.3759 Accuracy: 0.8697 Time: 17.55208  | Val Loss: 0.4844 Accuracy: 0.8432\n",
      "Epoch: 23/130 Train Loss: 0.3702 Accuracy: 0.8716 Time: 17.13646  | Val Loss: 0.3894 Accuracy: 0.8728\n",
      "Epoch: 24/130 Train Loss: 0.3603 Accuracy: 0.8761 Time: 17.87134  | Val Loss: 0.3754 Accuracy: 0.8751\n",
      "Epoch: 25/130 Train Loss: 0.3634 Accuracy: 0.8746 Time: 17.17329  | Val Loss: 0.3875 Accuracy: 0.8692\n",
      "Epoch: 26/130 Train Loss: 0.3604 Accuracy: 0.8740 Time: 17.95934  | Val Loss: 0.4064 Accuracy: 0.8586\n",
      "Epoch: 27/130 Train Loss: 0.3545 Accuracy: 0.8768 Time: 17.80893  | Val Loss: 0.4529 Accuracy: 0.8543\n",
      "Epoch: 28/130 Train Loss: 0.3495 Accuracy: 0.8796 Time: 17.38956  | Val Loss: 0.5211 Accuracy: 0.8311\n",
      "Epoch: 29/130 Train Loss: 0.3437 Accuracy: 0.8813 Time: 17.94781  | Val Loss: 0.3555 Accuracy: 0.8786\n",
      "Epoch: 30/130 Train Loss: 0.3458 Accuracy: 0.8811 Time: 18.16800  | Val Loss: 0.4180 Accuracy: 0.8569\n",
      "Epoch: 31/130 Train Loss: 0.2266 Accuracy: 0.9236 Time: 17.72199  | Val Loss: 0.2504 Accuracy: 0.9144\n",
      "Epoch: 32/130 Train Loss: 0.1937 Accuracy: 0.9354 Time: 18.87375  | Val Loss: 0.2497 Accuracy: 0.9170\n",
      "Epoch: 33/130 Train Loss: 0.1775 Accuracy: 0.9392 Time: 17.74435  | Val Loss: 0.2355 Accuracy: 0.9200\n",
      "Epoch: 34/130 Train Loss: 0.1659 Accuracy: 0.9442 Time: 19.28171  | Val Loss: 0.2458 Accuracy: 0.9204\n",
      "Epoch: 35/130 Train Loss: 0.1610 Accuracy: 0.9435 Time: 16.82600  | Val Loss: 0.2391 Accuracy: 0.9239\n",
      "Epoch: 36/130 Train Loss: 0.1561 Accuracy: 0.9461 Time: 17.14469  | Val Loss: 0.2521 Accuracy: 0.9199\n",
      "Epoch: 37/130 Train Loss: 0.1496 Accuracy: 0.9481 Time: 19.20451  | Val Loss: 0.2495 Accuracy: 0.9189\n",
      "Epoch: 38/130 Train Loss: 0.1458 Accuracy: 0.9499 Time: 17.50630  | Val Loss: 0.2522 Accuracy: 0.9212\n",
      "Epoch: 39/130 Train Loss: 0.1408 Accuracy: 0.9508 Time: 18.07681  | Val Loss: 0.2431 Accuracy: 0.9257\n",
      "Epoch: 40/130 Train Loss: 0.1362 Accuracy: 0.9527 Time: 17.21312  | Val Loss: 0.2500 Accuracy: 0.9227\n",
      "Epoch: 41/130 Train Loss: 0.1344 Accuracy: 0.9526 Time: 17.52894  | Val Loss: 0.2575 Accuracy: 0.9197\n",
      "Epoch: 42/130 Train Loss: 0.1330 Accuracy: 0.9529 Time: 17.97257  | Val Loss: 0.2510 Accuracy: 0.9239\n",
      "Epoch: 43/130 Train Loss: 0.1271 Accuracy: 0.9548 Time: 17.06664  | Val Loss: 0.2490 Accuracy: 0.9262\n",
      "Epoch: 44/130 Train Loss: 0.1287 Accuracy: 0.9551 Time: 16.96210  | Val Loss: 0.2656 Accuracy: 0.9193\n",
      "Epoch: 45/130 Train Loss: 0.1247 Accuracy: 0.9567 Time: 17.78869  | Val Loss: 0.2568 Accuracy: 0.9232\n",
      "Epoch: 46/130 Train Loss: 0.1214 Accuracy: 0.9573 Time: 17.39337  | Val Loss: 0.2482 Accuracy: 0.9242\n",
      "Epoch: 47/130 Train Loss: 0.1208 Accuracy: 0.9574 Time: 16.86210  | Val Loss: 0.2833 Accuracy: 0.9160\n",
      "Epoch: 48/130 Train Loss: 0.1167 Accuracy: 0.9593 Time: 18.85520  | Val Loss: 0.2706 Accuracy: 0.9233\n",
      "Epoch: 49/130 Train Loss: 0.1123 Accuracy: 0.9604 Time: 18.11471  | Val Loss: 0.2571 Accuracy: 0.9231\n",
      "Epoch: 50/130 Train Loss: 0.1096 Accuracy: 0.9618 Time: 17.03317  | Val Loss: 0.2676 Accuracy: 0.9227\n",
      "Epoch: 51/130 Train Loss: 0.1098 Accuracy: 0.9614 Time: 17.84314  | Val Loss: 0.2625 Accuracy: 0.9236\n",
      "Epoch: 52/130 Train Loss: 0.1107 Accuracy: 0.9611 Time: 17.81370  | Val Loss: 0.2795 Accuracy: 0.9224\n",
      "Epoch: 53/130 Train Loss: 0.1102 Accuracy: 0.9609 Time: 17.95859  | Val Loss: 0.2579 Accuracy: 0.9254\n",
      "Epoch: 54/130 Train Loss: 0.1029 Accuracy: 0.9640 Time: 17.32025  | Val Loss: 0.2927 Accuracy: 0.9169\n",
      "Epoch: 55/130 Train Loss: 0.1067 Accuracy: 0.9622 Time: 16.77592  | Val Loss: 0.2596 Accuracy: 0.9260\n",
      "Epoch: 56/130 Train Loss: 0.1017 Accuracy: 0.9639 Time: 17.60509  | Val Loss: 0.2697 Accuracy: 0.9248\n",
      "Epoch: 57/130 Train Loss: 0.1028 Accuracy: 0.9643 Time: 17.60739  | Val Loss: 0.2513 Accuracy: 0.9276\n",
      "Epoch: 58/130 Train Loss: 0.1011 Accuracy: 0.9652 Time: 17.41295  | Val Loss: 0.2821 Accuracy: 0.9195\n",
      "Epoch: 59/130 Train Loss: 0.0989 Accuracy: 0.9644 Time: 17.22101  | Val Loss: 0.2704 Accuracy: 0.9232\n",
      "Epoch: 60/130 Train Loss: 0.0985 Accuracy: 0.9650 Time: 16.88318  | Val Loss: 0.2580 Accuracy: 0.9269\n",
      "Epoch: 61/130 Train Loss: 0.0808 Accuracy: 0.9720 Time: 17.69168  | Val Loss: 0.2462 Accuracy: 0.9319\n",
      "Epoch: 62/130 Train Loss: 0.0742 Accuracy: 0.9746 Time: 18.19585  | Val Loss: 0.2484 Accuracy: 0.9323\n",
      "Epoch: 63/130 Train Loss: 0.0720 Accuracy: 0.9754 Time: 16.39715  | Val Loss: 0.2441 Accuracy: 0.9324\n",
      "Epoch: 64/130 Train Loss: 0.0677 Accuracy: 0.9778 Time: 16.56033  | Val Loss: 0.2487 Accuracy: 0.9309\n",
      "Epoch: 65/130 Train Loss: 0.0663 Accuracy: 0.9777 Time: 18.00584  | Val Loss: 0.2492 Accuracy: 0.9307\n",
      "Epoch: 66/130 Train Loss: 0.0684 Accuracy: 0.9769 Time: 17.53078  | Val Loss: 0.2515 Accuracy: 0.9296\n",
      "Epoch: 67/130 Train Loss: 0.0629 Accuracy: 0.9792 Time: 17.71211  | Val Loss: 0.2431 Accuracy: 0.9327\n",
      "Epoch: 68/130 Train Loss: 0.0643 Accuracy: 0.9786 Time: 18.54269  | Val Loss: 0.2525 Accuracy: 0.9285\n",
      "Epoch: 69/130 Train Loss: 0.0626 Accuracy: 0.9797 Time: 19.82094  | Val Loss: 0.2520 Accuracy: 0.9302\n",
      "Epoch: 70/130 Train Loss: 0.0631 Accuracy: 0.9791 Time: 17.58669  | Val Loss: 0.2503 Accuracy: 0.9299\n",
      "Epoch: 71/130 Train Loss: 0.0637 Accuracy: 0.9789 Time: 17.56242  | Val Loss: 0.2534 Accuracy: 0.9309\n",
      "Epoch: 72/130 Train Loss: 0.0596 Accuracy: 0.9805 Time: 18.58756  | Val Loss: 0.2526 Accuracy: 0.9304\n",
      "Epoch: 73/130 Train Loss: 0.0601 Accuracy: 0.9799 Time: 17.64851  | Val Loss: 0.2592 Accuracy: 0.9306\n",
      "Epoch: 74/130 Train Loss: 0.0579 Accuracy: 0.9812 Time: 17.50262  | Val Loss: 0.2473 Accuracy: 0.9327\n",
      "Epoch: 75/130 Train Loss: 0.0586 Accuracy: 0.9804 Time: 17.91234  | Val Loss: 0.2521 Accuracy: 0.9309\n",
      "Epoch: 76/130 Train Loss: 0.0584 Accuracy: 0.9807 Time: 17.14570  | Val Loss: 0.2587 Accuracy: 0.9301\n",
      "Epoch: 77/130 Train Loss: 0.0581 Accuracy: 0.9806 Time: 17.19149  | Val Loss: 0.2529 Accuracy: 0.9319\n",
      "Epoch: 78/130 Train Loss: 0.0570 Accuracy: 0.9807 Time: 16.96210  | Val Loss: 0.2582 Accuracy: 0.9301\n",
      "Epoch: 79/130 Train Loss: 0.0557 Accuracy: 0.9809 Time: 16.58609  | Val Loss: 0.2616 Accuracy: 0.9309\n",
      "Epoch: 80/130 Train Loss: 0.0549 Accuracy: 0.9818 Time: 17.39586  | Val Loss: 0.2598 Accuracy: 0.9310\n",
      "Epoch: 81/130 Train Loss: 0.0554 Accuracy: 0.9815 Time: 16.94331  | Val Loss: 0.2672 Accuracy: 0.9287\n",
      "Epoch: 82/130 Train Loss: 0.0548 Accuracy: 0.9823 Time: 17.64095  | Val Loss: 0.2616 Accuracy: 0.9307\n",
      "Epoch: 83/130 Train Loss: 0.0537 Accuracy: 0.9819 Time: 17.46242  | Val Loss: 0.2669 Accuracy: 0.9293\n",
      "Epoch: 84/130 Train Loss: 0.0544 Accuracy: 0.9821 Time: 18.27840  | Val Loss: 0.2616 Accuracy: 0.9315\n",
      "Epoch: 85/130 Train Loss: 0.0553 Accuracy: 0.9817 Time: 16.87354  | Val Loss: 0.2719 Accuracy: 0.9287\n",
      "Epoch: 86/130 Train Loss: 0.0523 Accuracy: 0.9830 Time: 18.00400  | Val Loss: 0.2684 Accuracy: 0.9306\n",
      "Epoch: 87/130 Train Loss: 0.0539 Accuracy: 0.9823 Time: 18.45664  | Val Loss: 0.2626 Accuracy: 0.9318\n",
      "Epoch: 88/130 Train Loss: 0.0530 Accuracy: 0.9824 Time: 18.39390  | Val Loss: 0.2614 Accuracy: 0.9314\n",
      "Epoch: 89/130 Train Loss: 0.0526 Accuracy: 0.9822 Time: 18.03890  | Val Loss: 0.2641 Accuracy: 0.9311\n",
      "Epoch: 90/130 Train Loss: 0.0526 Accuracy: 0.9823 Time: 17.40164  | Val Loss: 0.2732 Accuracy: 0.9288\n",
      "Epoch: 91/130 Train Loss: 0.0496 Accuracy: 0.9832 Time: 16.23064  | Val Loss: 0.2665 Accuracy: 0.9313\n",
      "Epoch: 92/130 Train Loss: 0.0505 Accuracy: 0.9834 Time: 17.00235  | Val Loss: 0.2712 Accuracy: 0.9307\n",
      "Epoch: 93/130 Train Loss: 0.0514 Accuracy: 0.9834 Time: 17.71904  | Val Loss: 0.2584 Accuracy: 0.9321\n",
      "Epoch: 94/130 Train Loss: 0.0505 Accuracy: 0.9835 Time: 16.39217  | Val Loss: 0.2724 Accuracy: 0.9292\n",
      "Epoch: 95/130 Train Loss: 0.0494 Accuracy: 0.9839 Time: 18.72487  | Val Loss: 0.2703 Accuracy: 0.9306\n",
      "Epoch: 96/130 Train Loss: 0.0478 Accuracy: 0.9845 Time: 17.11031  | Val Loss: 0.2636 Accuracy: 0.9313\n",
      "Epoch: 97/130 Train Loss: 0.0501 Accuracy: 0.9838 Time: 17.66240  | Val Loss: 0.2762 Accuracy: 0.9281\n",
      "Epoch: 98/130 Train Loss: 0.0499 Accuracy: 0.9835 Time: 18.01217  | Val Loss: 0.2764 Accuracy: 0.9289\n",
      "Epoch: 99/130 Train Loss: 0.0490 Accuracy: 0.9838 Time: 17.36470  | Val Loss: 0.2681 Accuracy: 0.9306\n",
      "Epoch: 100/130 Train Loss: 0.0502 Accuracy: 0.9835 Time: 16.73419  | Val Loss: 0.2723 Accuracy: 0.9298\n",
      "Epoch: 101/130 Train Loss: 0.0497 Accuracy: 0.9836 Time: 18.01373  | Val Loss: 0.2699 Accuracy: 0.9308\n",
      "Epoch: 102/130 Train Loss: 0.0506 Accuracy: 0.9831 Time: 18.01654  | Val Loss: 0.2706 Accuracy: 0.9304\n",
      "Epoch: 103/130 Train Loss: 0.0503 Accuracy: 0.9838 Time: 17.90361  | Val Loss: 0.2682 Accuracy: 0.9298\n",
      "Epoch: 104/130 Train Loss: 0.0496 Accuracy: 0.9839 Time: 17.16979  | Val Loss: 0.2676 Accuracy: 0.9314\n",
      "Epoch: 105/130 Train Loss: 0.0496 Accuracy: 0.9840 Time: 18.04761  | Val Loss: 0.2656 Accuracy: 0.9306\n",
      "Epoch: 106/130 Train Loss: 0.0496 Accuracy: 0.9839 Time: 17.40299  | Val Loss: 0.2726 Accuracy: 0.9290\n",
      "Epoch: 107/130 Train Loss: 0.0494 Accuracy: 0.9836 Time: 17.40988  | Val Loss: 0.2703 Accuracy: 0.9314\n",
      "Epoch: 108/130 Train Loss: 0.0485 Accuracy: 0.9840 Time: 16.96399  | Val Loss: 0.2624 Accuracy: 0.9330\n",
      "Epoch: 109/130 Train Loss: 0.0489 Accuracy: 0.9841 Time: 17.37459  | Val Loss: 0.2699 Accuracy: 0.9309\n",
      "Epoch: 110/130 Train Loss: 0.0489 Accuracy: 0.9835 Time: 18.76614  | Val Loss: 0.2724 Accuracy: 0.9302\n",
      "Epoch: 111/130 Train Loss: 0.0474 Accuracy: 0.9844 Time: 16.83037  | Val Loss: 0.2734 Accuracy: 0.9305\n",
      "Epoch: 112/130 Train Loss: 0.0484 Accuracy: 0.9843 Time: 18.34296  | Val Loss: 0.2714 Accuracy: 0.9297\n",
      "Epoch: 113/130 Train Loss: 0.0500 Accuracy: 0.9834 Time: 17.73490  | Val Loss: 0.2712 Accuracy: 0.9298\n",
      "Epoch: 114/130 Train Loss: 0.0484 Accuracy: 0.9847 Time: 16.17659  | Val Loss: 0.2668 Accuracy: 0.9321\n",
      "Epoch: 115/130 Train Loss: 0.0470 Accuracy: 0.9853 Time: 17.62142  | Val Loss: 0.2684 Accuracy: 0.9309\n",
      "Epoch: 116/130 Train Loss: 0.0484 Accuracy: 0.9835 Time: 17.33343  | Val Loss: 0.2633 Accuracy: 0.9307\n",
      "Epoch: 117/130 Train Loss: 0.0490 Accuracy: 0.9841 Time: 16.27085  | Val Loss: 0.2711 Accuracy: 0.9309\n",
      "Epoch: 118/130 Train Loss: 0.0488 Accuracy: 0.9840 Time: 16.29444  | Val Loss: 0.2679 Accuracy: 0.9302\n",
      "Epoch: 119/130 Train Loss: 0.0479 Accuracy: 0.9842 Time: 17.12910  | Val Loss: 0.2606 Accuracy: 0.9321\n",
      "Epoch: 120/130 Train Loss: 0.0490 Accuracy: 0.9840 Time: 16.68809  | Val Loss: 0.2732 Accuracy: 0.9307\n",
      "Epoch: 121/130 Train Loss: 0.0469 Accuracy: 0.9848 Time: 17.00011  | Val Loss: 0.2742 Accuracy: 0.9310\n",
      "Epoch: 122/130 Train Loss: 0.0476 Accuracy: 0.9846 Time: 16.46254  | Val Loss: 0.2749 Accuracy: 0.9299\n",
      "Epoch: 123/130 Train Loss: 0.0477 Accuracy: 0.9846 Time: 17.29267  | Val Loss: 0.2718 Accuracy: 0.9294\n",
      "Epoch: 124/130 Train Loss: 0.0492 Accuracy: 0.9834 Time: 17.43985  | Val Loss: 0.2648 Accuracy: 0.9314\n",
      "Epoch: 125/130 Train Loss: 0.0478 Accuracy: 0.9842 Time: 17.24487  | Val Loss: 0.2719 Accuracy: 0.9304\n",
      "Epoch: 126/130 Train Loss: 0.0482 Accuracy: 0.9840 Time: 17.87159  | Val Loss: 0.2803 Accuracy: 0.9296\n",
      "Epoch: 127/130 Train Loss: 0.0476 Accuracy: 0.9841 Time: 15.93818  | Val Loss: 0.2720 Accuracy: 0.9311\n",
      "Epoch: 128/130 Train Loss: 0.0479 Accuracy: 0.9845 Time: 15.66384  | Val Loss: 0.2660 Accuracy: 0.9303\n",
      "Epoch: 129/130 Train Loss: 0.0466 Accuracy: 0.9850 Time: 18.67568  | Val Loss: 0.2722 Accuracy: 0.9302\n",
      "Epoch: 130/130 Train Loss: 0.0485 Accuracy: 0.9840 Time: 19.34425  | Val Loss: 0.2733 Accuracy: 0.9310\n",
      "#Parameter: 1261018 Accuracy: 0.9311\n"
     ]
    }
   ],
   "source": [
    "from hdd.models.cnn.densenet import (\n",
    "    DenseNetSmall40,\n",
    ")\n",
    "from hdd.train.classification_utils import (\n",
    "    naive_train_classification_model,\n",
    "    eval_image_classifier,\n",
    ")\n",
    "from hdd.models.nn_utils import count_trainable_parameter\n",
    "\n",
    "\n",
    "def train_net(\n",
    "    net,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    lr,\n",
    "    weight_decay,\n",
    "    step_size=30,\n",
    "    gamma=0.1,\n",
    "    max_epochs=130,\n",
    ") -> dict[str, list[float]]:\n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(\n",
    "        net.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay\n",
    "    )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer, step_size=step_size, gamma=gamma, last_epoch=-1\n",
    "    )\n",
    "    training_stats = naive_train_classification_model(\n",
    "        net,\n",
    "        criteria,\n",
    "        max_epochs,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        DEVICE,\n",
    "        optimizer,\n",
    "        scheduler,\n",
    "        verbose=True,\n",
    "    )\n",
    "    return training_stats\n",
    "\n",
    "\n",
    "net = DenseNetSmall40(num_classes=10, dropout=0.2, growth_rate=12).to(DEVICE)\n",
    "dense40_stats = train_net(\n",
    "    net,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "eval_result = eval_image_classifier(net, val_dataloader.dataset, DEVICE)\n",
    "ss = [result.gt_label == result.predicted_label for result in eval_result]\n",
    "print(f\"#Parameter: {count_trainable_parameter(net)} Accuracy: {sum(ss) / len(ss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b9e10",
   "metadata": {},
   "source": [
    "## Experiment on imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "654e4876",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdd.dataset.imagenette_in_memory import ImagenetteInMemory\n",
    "from hdd.data_util.transforms import RandomResize\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "TRAIN_MEAN = [0.4625, 0.4580, 0.4295]\n",
    "TRAIN_STD = [0.2452, 0.2390, 0.2469]\n",
    "train_dataset_transforms = transforms.Compose(\n",
    "    [\n",
    "        RandomResize([256, 296, 384]),  # 随机在三个size中选择一个进行resize\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=TRAIN_MEAN, std=TRAIN_STD),\n",
    "    ]\n",
    ")\n",
    "val_dataset_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=TRAIN_MEAN, std=TRAIN_STD),\n",
    "    ]\n",
    ")\n",
    "train_dataset = ImagenetteInMemory(\n",
    "    root=DATA_ROOT,\n",
    "    split=\"train\",\n",
    "    size=\"full\",\n",
    "    download=True,\n",
    "    transform=train_dataset_transforms,\n",
    ")\n",
    "val_dataset = ImagenetteInMemory(\n",
    "    root=DATA_ROOT,\n",
    "    split=\"val\",\n",
    "    size=\"full\",\n",
    "    download=True,\n",
    "    transform=val_dataset_transforms,\n",
    ")\n",
    "\n",
    "\n",
    "def build_dataloader(batch_size, train_dataset, val_dataset):\n",
    "    train_dataloader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=8\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=8\n",
    "    )\n",
    "    return train_dataloader, val_dataloader\n",
    "\n",
    "\n",
    "train_dataloader, val_dataloader = build_dataloader(32, train_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc71657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/130 Train Loss: 2.0372 Accuracy: 0.3088 Time: 9.17116  | Val Loss: 1.6869 Accuracy: 0.4594\n",
      "Epoch: 2/130 Train Loss: 1.5700 Accuracy: 0.4777 Time: 8.80793  | Val Loss: 1.5644 Accuracy: 0.4973\n",
      "Epoch: 3/130 Train Loss: 1.3361 Accuracy: 0.5636 Time: 8.83791  | Val Loss: 1.2912 Accuracy: 0.5987\n",
      "Epoch: 4/130 Train Loss: 1.2103 Accuracy: 0.6054 Time: 8.78721  | Val Loss: 0.9844 Accuracy: 0.6884\n",
      "Epoch: 5/130 Train Loss: 1.0998 Accuracy: 0.6436 Time: 9.02652  | Val Loss: 0.9751 Accuracy: 0.6736\n",
      "Epoch: 6/130 Train Loss: 1.0129 Accuracy: 0.6675 Time: 8.73941  | Val Loss: 0.9953 Accuracy: 0.6879\n",
      "Epoch: 7/130 Train Loss: 0.9695 Accuracy: 0.6869 Time: 8.75780  | Val Loss: 0.7781 Accuracy: 0.7483\n",
      "Epoch: 8/130 Train Loss: 0.9142 Accuracy: 0.7035 Time: 8.95806  | Val Loss: 0.9456 Accuracy: 0.6935\n",
      "Epoch: 9/130 Train Loss: 0.8782 Accuracy: 0.7177 Time: 8.93327  | Val Loss: 0.8223 Accuracy: 0.7376\n",
      "Epoch: 10/130 Train Loss: 0.8503 Accuracy: 0.7263 Time: 8.92591  | Val Loss: 0.8020 Accuracy: 0.7442\n",
      "Epoch: 11/130 Train Loss: 0.8176 Accuracy: 0.7394 Time: 8.92207  | Val Loss: 0.7100 Accuracy: 0.7748\n",
      "Epoch: 12/130 Train Loss: 0.7835 Accuracy: 0.7488 Time: 9.01608  | Val Loss: 0.7991 Accuracy: 0.7511\n",
      "Epoch: 13/130 Train Loss: 0.7458 Accuracy: 0.7548 Time: 8.97097  | Val Loss: 0.7291 Accuracy: 0.7679\n",
      "Epoch: 14/130 Train Loss: 0.7314 Accuracy: 0.7629 Time: 8.88046  | Val Loss: 0.8497 Accuracy: 0.7330\n",
      "Epoch: 15/130 Train Loss: 0.7011 Accuracy: 0.7719 Time: 8.88731  | Val Loss: 0.6253 Accuracy: 0.8008\n",
      "Epoch: 16/130 Train Loss: 0.7115 Accuracy: 0.7773 Time: 8.78699  | Val Loss: 0.6149 Accuracy: 0.8084\n",
      "Epoch: 17/130 Train Loss: 0.6851 Accuracy: 0.7733 Time: 8.69255  | Val Loss: 0.6643 Accuracy: 0.7878\n",
      "Epoch: 18/130 Train Loss: 0.6675 Accuracy: 0.7909 Time: 8.87655  | Val Loss: 0.6243 Accuracy: 0.8074\n",
      "Epoch: 19/130 Train Loss: 0.6475 Accuracy: 0.7905 Time: 9.07509  | Val Loss: 0.6312 Accuracy: 0.7929\n",
      "Epoch: 20/130 Train Loss: 0.6398 Accuracy: 0.7932 Time: 9.00522  | Val Loss: 0.7868 Accuracy: 0.7608\n",
      "Epoch: 21/130 Train Loss: 0.6231 Accuracy: 0.7986 Time: 8.94444  | Val Loss: 0.5600 Accuracy: 0.8176\n",
      "Epoch: 22/130 Train Loss: 0.6185 Accuracy: 0.7991 Time: 9.23851  | Val Loss: 0.4986 Accuracy: 0.8423\n",
      "Epoch: 23/130 Train Loss: 0.5983 Accuracy: 0.8043 Time: 9.29303  | Val Loss: 0.6043 Accuracy: 0.8076\n",
      "Epoch: 24/130 Train Loss: 0.5785 Accuracy: 0.8147 Time: 8.96099  | Val Loss: 0.5141 Accuracy: 0.8336\n",
      "Epoch: 25/130 Train Loss: 0.5871 Accuracy: 0.8102 Time: 9.13128  | Val Loss: 0.6852 Accuracy: 0.7918\n",
      "Epoch: 26/130 Train Loss: 0.5730 Accuracy: 0.8131 Time: 8.92935  | Val Loss: 0.6292 Accuracy: 0.8061\n",
      "Epoch: 27/130 Train Loss: 0.5683 Accuracy: 0.8151 Time: 9.02876  | Val Loss: 0.7253 Accuracy: 0.7712\n",
      "Epoch: 28/130 Train Loss: 0.5536 Accuracy: 0.8236 Time: 9.10406  | Val Loss: 0.5046 Accuracy: 0.8420\n",
      "Epoch: 29/130 Train Loss: 0.5523 Accuracy: 0.8185 Time: 9.53710  | Val Loss: 0.4876 Accuracy: 0.8456\n",
      "Epoch: 30/130 Train Loss: 0.5444 Accuracy: 0.8228 Time: 9.01722  | Val Loss: 0.5212 Accuracy: 0.8303\n",
      "Epoch: 31/130 Train Loss: 0.3923 Accuracy: 0.8787 Time: 8.99163  | Val Loss: 0.3637 Accuracy: 0.8841\n",
      "Epoch: 32/130 Train Loss: 0.3538 Accuracy: 0.8906 Time: 9.25382  | Val Loss: 0.3442 Accuracy: 0.8920\n",
      "Epoch: 33/130 Train Loss: 0.3302 Accuracy: 0.8941 Time: 8.97046  | Val Loss: 0.3370 Accuracy: 0.8907\n",
      "Epoch: 34/130 Train Loss: 0.3241 Accuracy: 0.8942 Time: 8.93260  | Val Loss: 0.3452 Accuracy: 0.8925\n",
      "Epoch: 35/130 Train Loss: 0.3260 Accuracy: 0.8977 Time: 9.14420  | Val Loss: 0.3412 Accuracy: 0.8912\n",
      "Epoch: 36/130 Train Loss: 0.3132 Accuracy: 0.8991 Time: 8.96222  | Val Loss: 0.3332 Accuracy: 0.8958\n",
      "Epoch: 37/130 Train Loss: 0.2994 Accuracy: 0.9026 Time: 8.79843  | Val Loss: 0.3297 Accuracy: 0.8978\n",
      "Epoch: 38/130 Train Loss: 0.2820 Accuracy: 0.9077 Time: 8.83939  | Val Loss: 0.3327 Accuracy: 0.8981\n",
      "Epoch: 39/130 Train Loss: 0.2737 Accuracy: 0.9127 Time: 8.94886  | Val Loss: 0.3319 Accuracy: 0.8950\n",
      "Epoch: 40/130 Train Loss: 0.2834 Accuracy: 0.9079 Time: 8.74024  | Val Loss: 0.3421 Accuracy: 0.8935\n",
      "Epoch: 41/130 Train Loss: 0.2666 Accuracy: 0.9135 Time: 8.82027  | Val Loss: 0.3323 Accuracy: 0.8968\n",
      "Epoch: 42/130 Train Loss: 0.2757 Accuracy: 0.9111 Time: 8.71298  | Val Loss: 0.3379 Accuracy: 0.8943\n",
      "Epoch: 43/130 Train Loss: 0.2556 Accuracy: 0.9184 Time: 9.19401  | Val Loss: 0.3457 Accuracy: 0.8953\n",
      "Epoch: 44/130 Train Loss: 0.2645 Accuracy: 0.9126 Time: 8.89114  | Val Loss: 0.3513 Accuracy: 0.8902\n",
      "Epoch: 45/130 Train Loss: 0.2543 Accuracy: 0.9183 Time: 8.75281  | Val Loss: 0.3396 Accuracy: 0.8943\n",
      "Epoch: 46/130 Train Loss: 0.2634 Accuracy: 0.9133 Time: 9.01902  | Val Loss: 0.3457 Accuracy: 0.8940\n",
      "Epoch: 47/130 Train Loss: 0.2620 Accuracy: 0.9155 Time: 8.73114  | Val Loss: 0.3396 Accuracy: 0.8953\n",
      "Epoch: 48/130 Train Loss: 0.2535 Accuracy: 0.9168 Time: 8.76410  | Val Loss: 0.3439 Accuracy: 0.8907\n",
      "Epoch: 49/130 Train Loss: 0.2462 Accuracy: 0.9206 Time: 9.11378  | Val Loss: 0.3504 Accuracy: 0.8927\n",
      "Epoch: 50/130 Train Loss: 0.2419 Accuracy: 0.9208 Time: 8.87902  | Val Loss: 0.3407 Accuracy: 0.8943\n",
      "Epoch: 51/130 Train Loss: 0.2403 Accuracy: 0.9212 Time: 8.73972  | Val Loss: 0.3464 Accuracy: 0.8973\n",
      "Epoch: 52/130 Train Loss: 0.2383 Accuracy: 0.9223 Time: 8.60754  | Val Loss: 0.3323 Accuracy: 0.8968\n",
      "Epoch: 53/130 Train Loss: 0.2338 Accuracy: 0.9254 Time: 8.80972  | Val Loss: 0.3406 Accuracy: 0.8932\n",
      "Epoch: 54/130 Train Loss: 0.2259 Accuracy: 0.9263 Time: 9.08188  | Val Loss: 0.3456 Accuracy: 0.8927\n",
      "Epoch: 55/130 Train Loss: 0.2293 Accuracy: 0.9242 Time: 8.71394  | Val Loss: 0.3545 Accuracy: 0.8907\n",
      "Epoch: 56/130 Train Loss: 0.2260 Accuracy: 0.9250 Time: 8.73378  | Val Loss: 0.3536 Accuracy: 0.8912\n",
      "Epoch: 57/130 Train Loss: 0.2261 Accuracy: 0.9283 Time: 8.54906  | Val Loss: 0.3357 Accuracy: 0.9006\n",
      "Epoch: 58/130 Train Loss: 0.2156 Accuracy: 0.9284 Time: 9.08229  | Val Loss: 0.3582 Accuracy: 0.8912\n",
      "Epoch: 59/130 Train Loss: 0.2230 Accuracy: 0.9250 Time: 8.73563  | Val Loss: 0.3394 Accuracy: 0.8978\n",
      "Epoch: 60/130 Train Loss: 0.2259 Accuracy: 0.9257 Time: 8.70979  | Val Loss: 0.3429 Accuracy: 0.8925\n",
      "Epoch: 61/130 Train Loss: 0.1890 Accuracy: 0.9402 Time: 8.53934  | Val Loss: 0.3353 Accuracy: 0.8961\n",
      "Epoch: 62/130 Train Loss: 0.1872 Accuracy: 0.9406 Time: 9.19215  | Val Loss: 0.3319 Accuracy: 0.8986\n",
      "Epoch: 63/130 Train Loss: 0.1703 Accuracy: 0.9448 Time: 8.71308  | Val Loss: 0.3225 Accuracy: 0.9019\n",
      "Epoch: 64/130 Train Loss: 0.1887 Accuracy: 0.9393 Time: 8.70225  | Val Loss: 0.3257 Accuracy: 0.9001\n",
      "Epoch: 65/130 Train Loss: 0.1774 Accuracy: 0.9442 Time: 8.60051  | Val Loss: 0.3276 Accuracy: 0.8996\n",
      "Epoch: 66/130 Train Loss: 0.1816 Accuracy: 0.9427 Time: 8.41381  | Val Loss: 0.3284 Accuracy: 0.8983\n",
      "Epoch: 67/130 Train Loss: 0.1816 Accuracy: 0.9411 Time: 8.54562  | Val Loss: 0.3221 Accuracy: 0.9017\n",
      "Epoch: 68/130 Train Loss: 0.1780 Accuracy: 0.9428 Time: 8.70298  | Val Loss: 0.3253 Accuracy: 0.9004\n",
      "Epoch: 69/130 Train Loss: 0.1649 Accuracy: 0.9472 Time: 9.04131  | Val Loss: 0.3341 Accuracy: 0.8973\n",
      "Epoch: 70/130 Train Loss: 0.1638 Accuracy: 0.9487 Time: 8.87157  | Val Loss: 0.3320 Accuracy: 0.8968\n",
      "Epoch: 71/130 Train Loss: 0.1667 Accuracy: 0.9475 Time: 8.71293  | Val Loss: 0.3292 Accuracy: 0.8983\n",
      "Epoch: 72/130 Train Loss: 0.1683 Accuracy: 0.9461 Time: 8.69725  | Val Loss: 0.3287 Accuracy: 0.9017\n",
      "Epoch: 73/130 Train Loss: 0.1775 Accuracy: 0.9423 Time: 8.69240  | Val Loss: 0.3319 Accuracy: 0.8989\n",
      "Epoch: 74/130 Train Loss: 0.1692 Accuracy: 0.9457 Time: 8.57681  | Val Loss: 0.3268 Accuracy: 0.9011\n",
      "Epoch: 75/130 Train Loss: 0.1753 Accuracy: 0.9440 Time: 8.85810  | Val Loss: 0.3323 Accuracy: 0.8989\n",
      "Epoch: 76/130 Train Loss: 0.1747 Accuracy: 0.9428 Time: 8.56010  | Val Loss: 0.3222 Accuracy: 0.9017\n",
      "Epoch: 77/130 Train Loss: 0.1712 Accuracy: 0.9448 Time: 8.62065  | Val Loss: 0.3260 Accuracy: 0.9014\n",
      "Epoch: 78/130 Train Loss: 0.1690 Accuracy: 0.9447 Time: 8.84058  | Val Loss: 0.3325 Accuracy: 0.8999\n",
      "Epoch: 79/130 Train Loss: 0.1679 Accuracy: 0.9459 Time: 8.92761  | Val Loss: 0.3299 Accuracy: 0.9017\n",
      "Epoch: 80/130 Train Loss: 0.1663 Accuracy: 0.9486 Time: 9.04137  | Val Loss: 0.3251 Accuracy: 0.9024\n",
      "Epoch: 81/130 Train Loss: 0.1691 Accuracy: 0.9466 Time: 9.54195  | Val Loss: 0.3302 Accuracy: 0.9017\n",
      "Epoch: 82/130 Train Loss: 0.1658 Accuracy: 0.9480 Time: 9.09410  | Val Loss: 0.3302 Accuracy: 0.8996\n",
      "Epoch: 83/130 Train Loss: 0.1642 Accuracy: 0.9460 Time: 9.20257  | Val Loss: 0.3280 Accuracy: 0.9024\n",
      "Epoch: 84/130 Train Loss: 0.1632 Accuracy: 0.9471 Time: 8.80599  | Val Loss: 0.3275 Accuracy: 0.9011\n",
      "Epoch: 85/130 Train Loss: 0.1632 Accuracy: 0.9468 Time: 9.11708  | Val Loss: 0.3384 Accuracy: 0.8994\n",
      "Epoch: 86/130 Train Loss: 0.1666 Accuracy: 0.9453 Time: 8.95403  | Val Loss: 0.3315 Accuracy: 0.8999\n",
      "Epoch: 87/130 Train Loss: 0.1601 Accuracy: 0.9494 Time: 8.94278  | Val Loss: 0.3296 Accuracy: 0.9029\n",
      "Epoch: 88/130 Train Loss: 0.1663 Accuracy: 0.9452 Time: 8.74910  | Val Loss: 0.3362 Accuracy: 0.8983\n",
      "Epoch: 89/130 Train Loss: 0.1640 Accuracy: 0.9457 Time: 8.79874  | Val Loss: 0.3313 Accuracy: 0.9027\n",
      "Epoch: 90/130 Train Loss: 0.1603 Accuracy: 0.9496 Time: 8.88920  | Val Loss: 0.3379 Accuracy: 0.8986\n",
      "Epoch: 91/130 Train Loss: 0.1597 Accuracy: 0.9486 Time: 8.87286  | Val Loss: 0.3284 Accuracy: 0.9017\n",
      "Epoch: 92/130 Train Loss: 0.1548 Accuracy: 0.9505 Time: 8.70657  | Val Loss: 0.3421 Accuracy: 0.8976\n",
      "Epoch: 93/130 Train Loss: 0.1561 Accuracy: 0.9499 Time: 8.75457  | Val Loss: 0.3337 Accuracy: 0.8999\n",
      "Epoch: 94/130 Train Loss: 0.1544 Accuracy: 0.9518 Time: 8.74977  | Val Loss: 0.3355 Accuracy: 0.9006\n",
      "Epoch: 95/130 Train Loss: 0.1651 Accuracy: 0.9481 Time: 9.02168  | Val Loss: 0.3334 Accuracy: 0.9017\n",
      "Epoch: 96/130 Train Loss: 0.1571 Accuracy: 0.9505 Time: 9.07668  | Val Loss: 0.3280 Accuracy: 0.9019\n",
      "Epoch: 97/130 Train Loss: 0.1451 Accuracy: 0.9549 Time: 8.74600  | Val Loss: 0.3411 Accuracy: 0.8973\n",
      "Epoch: 98/130 Train Loss: 0.1650 Accuracy: 0.9448 Time: 8.89666  | Val Loss: 0.3350 Accuracy: 0.9022\n",
      "Epoch: 99/130 Train Loss: 0.1547 Accuracy: 0.9497 Time: 9.02305  | Val Loss: 0.3307 Accuracy: 0.9006\n"
     ]
    }
   ],
   "source": [
    "from hdd.models.cnn.densenet import (\n",
    "    DenseNetBC121,\n",
    ")\n",
    "\n",
    "net = DenseNetBC121(num_classes=10, dropout=0.0, growth_rate=12).to(DEVICE)\n",
    "dense40_stats = train_net(\n",
    "    net,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    lr=0.1,\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "eval_result = eval_image_classifier(net, val_dataloader.dataset, DEVICE)\n",
    "ss = [result.gt_label == result.predicted_label for result in eval_result]\n",
    "print(f\"#Parameter: {count_trainable_parameter(net)} Accuracy: {sum(ss) / len(ss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f39431e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cu124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
